{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-4 Vision\n",
    "\n",
    "GPT-4 Turbo with Vision is a large multimodal model (LMM) developed by OpenAI that can analyze images and provide textual responses to questions about them. It incorporates both natural language processing and visual understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data/ingredients.png image below\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = Image.open('data/ingredients.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../credentials.env\")\n",
    "\n",
    "# 구성\n",
    "GPT4V_KEY = os.getenv('GPT_4_VISION_API_KEY')\n",
    "IMAGE_PATH = \"./data/ingredients.png\"\n",
    "encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": GPT4V_KEY,\n",
    "}\n",
    "\n",
    "# 요청을 위한 Payload\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are an AI assistant that helps people find information.\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/png;base64,{encoded_image}\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"이 사진에 대해서 설명해줘.\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"temperature\": 0.7,\n",
    "  \"top_p\": 0.95,\n",
    "  \"max_tokens\": 800\n",
    "}\n",
    "\n",
    "GPT4V_ENDPOINT = f\"{os.getenv('GPT_4_VISION_ENDPOINT')}openai/deployments/{os.getenv('GPT_4_VISION_DEPLOYMENT_NAME')}/chat/completions?api-version=2024-02-15-preview\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send request\n",
    "try:\n",
    "    response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
    "    response.raise_for_status()  # HTTP 요청이 실패한 상태 코드를 반환한 경우 HttpError를 발생시킵니다.\n",
    "except requests.RequestException as e:\n",
    "    raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
    "\n",
    "# Handle the response as needed (e.g., print or process)\n",
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
